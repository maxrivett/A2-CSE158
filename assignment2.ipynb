{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import gzip\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from lightfm import LightFM\n",
    "from scipy.sparse import coo_matrix\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "file_path = 'ratebeer.json.gz'\n",
    "\n",
    "\n",
    "with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "\n",
    "\n",
    "        # Fix single quotes to double quotes\n",
    "        line = line.replace(\"'\", '\"')\n",
    "        try:\n",
    "            dataset.append(json.loads(line))\n",
    "        except json.JSONDecodeError as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rating(ratings):\n",
    "    if type(ratings) == str:\n",
    "        num = int(ratings.split('/')[0])\n",
    "        den = int(ratings.split('/')[1])\n",
    "        return num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_abv(abv):\n",
    "    if abv.isnumeric():\n",
    "        return float(abv)\n",
    "    else:\n",
    "        return np.nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review/appearance'] = df['review/appearance'].apply(clean_rating)\n",
    "df['review/aroma'] = df['review/aroma'].apply(clean_rating)\n",
    "df['review/taste'] = df['review/taste'].apply(clean_rating)\n",
    "df['review/overall'] = df['review/overall'].apply(clean_rating)\n",
    "df['review/palate'] = df['review/palate'].apply(clean_rating)\n",
    "df['beer/ABV'] = pd.to_numeric(df['beer/ABV'].replace('-', np.nan), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_4 = df['beer/style'].value_counts().index[:4].tolist()\n",
    "top_10 = df['beer/style'].value_counts().index[:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "top4_df = df[df['beer/style'].isin(top_4)]\n",
    "top10_df = df[df['beer/style'].isin(top_10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_thresh4 = int((len(top4_df) * 0.8) // 1)\n",
    "\n",
    "train_thresh10 = int((len(top10_df) * 0.8) // 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train4 = top4_df[:train_thresh4]\n",
    "test4 = top4_df[train_thresh4:]\n",
    "\n",
    "train10 = top10_df[:train_thresh10]\n",
    "test10 = top10_df[train_thresh10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_X4 = train4[['review/appearance', 'review/aroma', 'review/palate', 'review/taste', 'review/overall']]\n",
    "train_y4 = train4['beer/style']\n",
    "test_X4 = test4[['review/appearance', 'review/aroma', 'review/palate', 'review/taste', 'review/overall']]\n",
    "test_y4 = test4['beer/style']\n",
    "\n",
    "train_X10 = train10[['review/appearance', 'review/aroma', 'review/palate', 'review/taste', 'review/overall']]\n",
    "train_y10 = train10['beer/style']\n",
    "test_X10 = test10[['review/appearance', 'review/aroma', 'review/palate', 'review/taste', 'review/overall']]\n",
    "test_y10 = test10['beer/style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/family/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/family/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = LogisticRegression()\n",
    "model4.fit(train_X4, train_y4)\n",
    "\n",
    "model10 = LogisticRegression()\n",
    "model10.fit(train_X10, train_y10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds4 = model4.predict(test_X4)\n",
    "\n",
    "preds10 = model10.predict(test_X10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for model 4: 0.5329164527250055\n",
      "Accuracy for model 10: 0.26604071060559137\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy for model 4: {(test_y4.values == preds4).mean()}\")\n",
    "\n",
    "print(f\"Accuracy for model 10: {(test_y10.values == preds10).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline with ABV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train4 = train4.dropna(subset = ['beer/ABV'])\n",
    "test4 = test4.dropna(subset = ['beer/ABV'])\n",
    "train10 = train10.dropna(subset = ['beer/ABV'])\n",
    "test10 = test10.dropna(subset = ['beer/ABV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X4 = train4[['review/appearance', 'review/aroma', 'review/palate', 'review/taste', 'review/overall', 'beer/ABV']]\n",
    "train_y4 = train4['beer/style']\n",
    "test_X4 = test4[['review/appearance', 'review/aroma', 'review/palate', 'review/taste', 'review/overall', 'beer/ABV']]\n",
    "test_y4 = test4['beer/style']\n",
    "\n",
    "train_X10 = train10[['review/appearance', 'review/aroma', 'review/palate', 'review/taste', 'review/overall', 'beer/ABV']]\n",
    "train_y10 = train10['beer/style']\n",
    "test_X10 = test10[['review/appearance', 'review/aroma', 'review/palate', 'review/taste', 'review/overall', 'beer/ABV']]\n",
    "test_y10 = test10['beer/style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/family/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/family/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = LogisticRegression()\n",
    "model4.fit(train_X4, train_y4)\n",
    "\n",
    "model10 = LogisticRegression()\n",
    "model10.fit(train_X10, train_y10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds4 = model4.predict(test_X4)\n",
    "\n",
    "preds10 = model10.predict(test_X10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for model 4: 0.7906065060876777\n",
      "Accuracy for model 10: 0.4623434601113173\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy for model 4: {(test_y4.values == preds4).mean()}\")\n",
    "\n",
    "print(f\"Accuracy for model 10: {(test_y10.values == preds10).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def stratified_sample(df, group_col, n_samples):\n",
    "    # Calculate the proportion of each group in the dataset\n",
    "    proportions = df[group_col].value_counts(normalize=True)\n",
    "    \n",
    "    # Determine the number of samples for each group based on the proportions\n",
    "    sample_counts = (proportions * n_samples).round().astype(int)\n",
    "    \n",
    "    # Sample rows for each group\n",
    "    sampled_df = pd.concat([\n",
    "        df[df[group_col] == group].sample(n=min(count, len(df[df[group_col] == group])), random_state=42)\n",
    "        for group, count in sample_counts.items()\n",
    "    ])\n",
    "    \n",
    "    return sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "top4_sampled = stratified_sample(top4_df, group_col=\"beer/style\", n_samples=200000)\n",
    "top10_sampled = stratified_sample(top10_df, group_col=\"beer/style\", n_samples=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stop_words = ['ipa', 'stout', 'belgian', 'lager', 'pale', 'india',\n",
    "                    'ipas', 'stouts', 'lagers', 'pales','ale', 'ales', 'dipa',\n",
    "                    'dipas']  # Add words you want to exclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 4 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.84695\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare the data\n",
    "top4_sampled['beer/style'] = LabelEncoder().fit_transform(top4_sampled['beer/style'])  # Encode the target variable\n",
    "top4_sampled['clean_text'] = top4_sampled['review/text'].str.lower().str.replace('[^\\w\\s]', '', regex=True)  # Clean text data\n",
    "\n",
    "vectorizer4 = TfidfVectorizer(max_features=100, stop_words=custom_stop_words)  # Limit features for simplicity\n",
    "text_features4 = vectorizer4.fit_transform(top4_sampled['clean_text']).toarray()\n",
    "\n",
    "# Step 3: Combine numerical features and text features\n",
    "numerical_features4 = top4_sampled[['review/appearance', 'review/aroma', 'review/palate', 'review/taste', 'review/overall']]\n",
    "combined_features4 = np.hstack((numerical_features4, text_features4))  # Combine arrays\n",
    "\n",
    "# Step 4: Split data\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(combined_features4, top4_sampled['beer/style'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Train a model\n",
    "model4 = LogisticRegression(max_iter=500)  # Increase max_iter to avoid convergence issues\n",
    "model4.fit(X_train4, y_train4)\n",
    "\n",
    "# Step 6: Make predictions and evaluate\n",
    "preds4 = model4.predict(X_test4)\n",
    "accuracy4 = accuracy_score(y_test4, preds4)\n",
    "print(f\"Model Accuracy: {accuracy4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alcohol', 'all', 'amber', 'an', 'and', 'aroma', 'as', 'at', 'be',\n",
       "       'beer', 'big', 'bit', 'bitter', 'bitterness', 'black', 'body',\n",
       "       'bottle', 'brown', 'but', 'by', 'caramel', 'carbonation',\n",
       "       'chocolate', 'citrus', 'clear', 'coffee', 'color', 'creamy',\n",
       "       'dark', 'dry', 'finish', 'flavor', 'for', 'from', 'fruit',\n",
       "       'fruity', 'golden', 'good', 'great', 'had', 'has', 'have', 'head',\n",
       "       'hop', 'hoppy', 'hops', 'in', 'is', 'it', 'its', 'just', 'lacing',\n",
       "       'light', 'like', 'little', 'malt', 'malts', 'malty', 'medium',\n",
       "       'more', 'mouthfeel', 'much', 'my', 'nice', 'no', 'nose', 'not',\n",
       "       'notes', 'of', 'on', 'one', 'orange', 'palate', 'pine', 'pours',\n",
       "       'quite', 'really', 'roasted', 'slightly', 'small', 'smooth',\n",
       "       'some', 'strong', 'sweet', 'taste', 'than', 'that', 'the', 'there',\n",
       "       'thick', 'thin', 'this', 'to', 'too', 'very', 'was', 'well',\n",
       "       'white', 'with', 'you'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer4.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 10 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.53925\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare the data\n",
    "top10_sampled['beer/style'] = LabelEncoder().fit_transform(top10_sampled['beer/style'])  # Encode the target variable\n",
    "top10_sampled['clean_text'] = top10_sampled['review/text'].str.lower().str.replace('[^\\w\\s]', '', regex=True)  # Clean text data\n",
    "\n",
    "vectorizer10 = TfidfVectorizer(max_features=100, stop_words=custom_stop_words)  # Limit features for simplicity\n",
    "text_features10 = vectorizer10.fit_transform(top10_sampled['clean_text']).toarray()\n",
    "\n",
    "# Step 3: Combine numerical features and text features\n",
    "numerical_features10 = top10_sampled[['review/appearance', 'review/aroma', 'review/palate', 'review/taste', 'review/overall']]\n",
    "combined_features10 = np.hstack((numerical_features10, text_features10))  # Combine arrays\n",
    "\n",
    "# Step 4: Split data\n",
    "X_train10, X_test10, y_train10, y_test10 = train_test_split(combined_features10, top10_sampled['beer/style'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Train a model\n",
    "model10 = LogisticRegression(max_iter=500)  # Increase max_iter to avoid convergence issues\n",
    "model10.fit(X_train10, y_train10)\n",
    "\n",
    "# Step 6: Make predictions and evaluate\n",
    "preds10 = model10.predict(X_test10)\n",
    "accuracy10 = accuracy_score(y_test10, preds10)\n",
    "print(f\"Model Accuracy: {accuracy10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alcohol', 'all', 'amber', 'an', 'and', 'are', 'aroma', 'as', 'at',\n",
       "       'be', 'beer', 'big', 'bit', 'bitter', 'bitterness', 'black',\n",
       "       'body', 'bottle', 'brown', 'but', 'by', 'caramel', 'carbonation',\n",
       "       'chocolate', 'citrus', 'clear', 'coffee', 'color', 'creamy',\n",
       "       'dark', 'dry', 'finish', 'flavor', 'for', 'from', 'fruit',\n",
       "       'fruity', 'golden', 'good', 'grapefruit', 'great', 'had', 'has',\n",
       "       'head', 'hop', 'hoppy', 'hops', 'in', 'is', 'it', 'its', 'just',\n",
       "       'lacing', 'light', 'like', 'little', 'malt', 'malts', 'malty',\n",
       "       'medium', 'more', 'mouthfeel', 'much', 'my', 'nice', 'no', 'nose',\n",
       "       'not', 'notes', 'of', 'on', 'one', 'orange', 'palate', 'pine',\n",
       "       'pours', 'quite', 'really', 'roasted', 'slightly', 'small',\n",
       "       'smooth', 'some', 'strong', 'sweet', 'sweetness', 'taste', 'than',\n",
       "       'that', 'the', 'there', 'thin', 'this', 'to', 'too', 'very', 'was',\n",
       "       'well', 'white', 'with'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer10.get_feature_names_out()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
